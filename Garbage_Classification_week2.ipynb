{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO/OZseeeB/7l8w9Esg+YgE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bhoomika685/Garbage_Classificcation-using-EfficientNet/blob/main/Garbage_Classification_week2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q tensorflow matplotlib scikit-learn\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D\n",
        "from tensorflow.keras.applications import EfficientNetV2L\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "import os"
      ],
      "metadata": {
        "id": "yNaUpiAcxBm1"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "zip_path = '/content/archive (1).zip'  # Change if your file has a different name\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/garbage_data')"
      ],
      "metadata": {
        "id": "2cV2LpJAErv2"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'/content/garbage_data/Garbage classification/Garbage classification'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "bpcIhU0dEz69",
        "outputId": "0349edd7-cfcb-498b-febc-44ca8444ecee"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/garbage_data/Garbage classification/Garbage classification'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    validation_split=0.2,\n",
        "    rotation_range=30,\n",
        "    zoom_range=0.2,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")"
      ],
      "metadata": {
        "id": "HA2ao1W1GvDE"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_gen = train_datagen.flow_from_directory(\n",
        "    '/content/garbage_data/Garbage classification/Garbage classification',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "val_gen = train_datagen.flow_from_directory(\n",
        "    '/content/garbage_data/Garbage classification/Garbage classification',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset='validation'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MHjYuRr8I8J6",
        "outputId": "3811a7fd-3eba-495b-e6e9-31080103f617"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2024 images belonging to 6 classes.\n",
            "Found 503 images belonging to 6 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import EfficientNetV2L\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
        "\n",
        "base_model = EfficientNetV2L(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "base_model.trainable = False  # freeze base model initially\n",
        "\n",
        "model = Sequential([\n",
        "    base_model,\n",
        "    GlobalAveragePooling2D(),\n",
        "    Dropout(0.3),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    Dense(train_gen.num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "fdUQNHpPKDBJ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model.trainable = True\n",
        "\n",
        "for layer in base_model.layers[:-20]:\n",
        "    layer.trainable = False\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(1e-5),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "B8S0r_ZNKOM6"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "# Define callbacks again\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "checkpoint = ModelCheckpoint(\"fine_tuned_model.h5\", save_best_only=True)\n",
        "\n",
        "# Train for 3–5 epochs\n",
        "fine_tune_history = model.fit(\n",
        "    train_gen,\n",
        "    validation_data=val_gen,\n",
        "    epochs=5,\n",
        "    callbacks=[early_stop, checkpoint]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9mgx0UmwKeFS",
        "outputId": "58ba974f-2087-4665-be6d-1764df9158b1"
      },
      "execution_count": 14,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22s/step - accuracy: 0.1408 - loss: 1.8002 "
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1813s\u001b[0m 27s/step - accuracy: 0.1411 - loss: 1.8001 - val_accuracy: 0.2068 - val_loss: 1.7867\n",
            "Epoch 2/5\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21s/step - accuracy: 0.2268 - loss: 1.7809 "
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1694s\u001b[0m 27s/step - accuracy: 0.2268 - loss: 1.7808 - val_accuracy: 0.3062 - val_loss: 1.7697\n",
            "Epoch 3/5\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21s/step - accuracy: 0.2310 - loss: 1.7674 "
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1675s\u001b[0m 26s/step - accuracy: 0.2311 - loss: 1.7673 - val_accuracy: 0.2823 - val_loss: 1.7529\n",
            "Epoch 4/5\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21s/step - accuracy: 0.2685 - loss: 1.7492 "
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1678s\u001b[0m 26s/step - accuracy: 0.2685 - loss: 1.7491 - val_accuracy: 0.2982 - val_loss: 1.7292\n",
            "Epoch 5/5\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21s/step - accuracy: 0.2915 - loss: 1.7214 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1706s\u001b[0m 26s/step - accuracy: 0.2914 - loss: 1.7214 - val_accuracy: 0.3241 - val_loss: 1.7014\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "\n",
        "# Load image and preprocess\n",
        "img_path = '/content/paper.jpeg'  # Change to your image name\n",
        "img = image.load_img(img_path, target_size=(224, 224))\n",
        "img_array = image.img_to_array(img) / 255.0\n",
        "img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "# Predict\n",
        "pred = model.predict(img_array)\n",
        "predicted_class = np.argmax(pred)\n",
        "confidence = np.max(pred)\n",
        "\n",
        "# Get class labels\n",
        "class_labels = list(train_gen.class_indices.keys())\n",
        "\n",
        "print(f\"🧠 Predicted Class: {class_labels[predicted_class]}\")\n",
        "print(f\"📊 Confidence: {confidence:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FNJyo0p8svhE",
        "outputId": "cc63dac3-a18a-49e2-f4ad-ddfbb055f88d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 759ms/step\n",
            "🧠 Predicted Class: paper\n",
            "📊 Confidence: 0.24\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_labels = list(train_gen.class_indices.keys())\n",
        "print(class_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QxOEfxxQtUcz",
        "outputId": "44d92323-642e-47ff-c4a9-28b6c1cb892b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['cardboard', 'glass', 'metal', 'paper', 'plastic', 'trash']\n"
          ]
        }
      ]
    }
  ]
}